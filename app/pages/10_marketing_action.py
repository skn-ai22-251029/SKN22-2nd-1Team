# # import streamlit as st
# # import pandas as pd
# # import sys
# # import requests
# # from io import BytesIO
# # from pathlib import Path
# from ui.header import render_header

# # =========================================================
# # [STEP 1] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (Path ê¸°ë°˜, OS ë…ë¦½)
# # =========================================================
# CURRENT_FILE = Path(__file__).resolve()
# APP_DIR = CURRENT_FILE.parents[1]
# PROJECT_ROOT = CURRENT_FILE.parents[2]

# if str(PROJECT_ROOT) not in sys.path:
#     sys.path.insert(0, str(PROJECT_ROOT))
# if str(APP_DIR) not in sys.path:
#     sys.path.insert(0, str(APP_DIR))

# # =========================================================
# # [STEP 2] ëª¨ë“ˆ ì„í¬íŠ¸
# # =========================================================
# from adapters.model_loader import JoblibArtifactLoader
# from adapters.purchase_intent_pr_auc_adapter import PurchaseIntentPRAUCModelAdapter
# from service.CustomerCareCenter import PurchaseIntentService

# # =========================================================
# # [STEP 3] ëª¨ë¸ ë¡œë”©
# # - ğŸ”§ ìˆ˜ì • í•µì‹¬:
# #   PurchaseIntentPRAUCModelAdapterëŠ” "ModelArtifact"ê°€ ì•„ë‹ˆë¼
# #   "artifact_path(ê²½ë¡œ)"ë¥¼ ë°›ë„ë¡ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë¯€ë¡œ,
# #   adapterì—ëŠ” ê²½ë¡œë¥¼ ì „ë‹¬í•´ì•¼ í•¨.
# # =========================================================
# @st.cache_resource
# def init_service():
#     artifact_path = PROJECT_ROOT / "artifacts" / "best_pr_auc_balancedrf.joblib"

#     # ğŸ”§ ìˆ˜ì •: íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬ (ë‹¤ë¥¸ PCì—ì„œë„ ì›ì¸ íŒŒì•… ì‰¬ì›€)
#     if not artifact_path.exists():
#         st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {artifact_path}")
#         st.stop()

#     # ğŸ”§ ìˆ˜ì •: adapterëŠ” "artifact ê°ì²´"ê°€ ì•„ë‹ˆë¼ "ê²½ë¡œ"ë¥¼ ë°›ëŠ”ë‹¤
#     adapter = PurchaseIntentPRAUCModelAdapter(artifact_path)

#     # service ìƒì„±
#     service = PurchaseIntentService(adapter)

#     # (ì„ íƒ) artifactë¥¼ ê¼­ ë°˜í™˜í•´ì•¼ í•œë‹¤ë©´ loaderë¡œ ë”°ë¡œ ë¡œë“œí•´ì„œ ë°˜í™˜ ê°€ëŠ¥
#     # ë‹¨, adapterê°€ ë‚´ë¶€ì—ì„œë„ ë¡œë“œí•  ìˆ˜ ìˆì–´ "ì¤‘ë³µ ë¡œë”©"ì´ ë  ìˆ˜ ìˆìŒ.
#     loader = JoblibArtifactLoader(artifact_path)
#     artifact = loader.load()

#     return service, adapter, artifact


# service, adapter, artifact = init_service()

# # =========================================================
# # [STEP 4] ë°ì´í„° ë¡œë“œ (UIìš© ìƒ˜í”Œ)
# # =========================================================
# @st.cache_data
# def load_data():
#     data_path = PROJECT_ROOT / "data" / "processed" / "test.csv"
#     if not data_path.exists():
#         st.error(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_path}")
#         st.stop()
#     return pd.read_csv(data_path)

# # ê¸°ì¡´ ìœ ì§€: 30ê°œ ì„¸ì…˜ ì‚¬ìš©
# df = load_data().head(30)

# # =========================================================
# # [ìœ ì§€] ê·¸ë£¹ë³„ Google Drive ì´ë¯¸ì§€ (10ê°œ)
# # =========================================================
# GROUP_IMAGE_MAP = {
#     1: "https://drive.google.com/uc?id=1C_FatsRQqIQPnygwx3McU4NcZZiRiBFp",
#     2: "https://drive.google.com/uc?id=1KB0J8zrm7ZFC4FvAcL3Z1r831ZBZpKJR",
#     3: "https://drive.google.com/uc?id=1n7l5AhZIU46u7vD6UxBk7xWSaraVMDao",
#     4: "https://drive.google.com/uc?id=1tmKyCJ_qhVv0050H9DPNdckhgXV0QwBt",
#     5: "https://drive.google.com/uc?id=1o3XvxRP9-iN80cO8T_aVPoA04CMk94hh",
#     6: "https://drive.google.com/uc?id=1QUXQMxvR0b7Gyx-KsHidAA6kVg8nFp_Y",
#     7: "https://drive.google.com/uc?id=1yJ5An-fs3J8PlADZ4NYUp4ySiFh4Okct",
#     8: "https://drive.google.com/uc?id=1u7eZMaBMpQ2aqg5A9BRw5BP1eKu6Kw4m",
#     9: "https://drive.google.com/uc?id=1kU9k2cCKkHRNnHhLCYKy4QsIQdTYAyCc",
#     10: "https://drive.google.com/uc?id=1kZpn2fKK2yC1PImdHo2CwQ61DVWf9qSy",
# }

# @st.cache_data
# def load_image_from_drive(url: str):
#     try:
#         response = requests.get(url, timeout=10)
#         if response.status_code == 200:
#             return BytesIO(response.content)
#     except Exception:
#         return None
#     return None

# # =========================================================
# # [ì¶”ê°€] ê°œë°œ ì¤‘ ìºì‹œ ì´ˆê¸°í™” ë²„íŠ¼
# # - Streamlit ìºì‹œ ë•Œë¬¸ì— ì½”ë“œ ìˆ˜ì •ì´ ë°˜ì˜ ì•ˆ ë˜ëŠ” ìƒí™© ë°©ì§€
# # =========================================================
# with st.sidebar:
#     if st.button("ìºì‹œ ì´ˆê¸°í™”(ê°œë°œìš©)"):
#         st.cache_data.clear()
#         st.cache_resource.clear()
#         st.rerun()

# # =========================================================
# # [UI]
# # =========================================================
# render_header()
# st.title("ğŸ¯ ë§ˆì¼€íŒ… ì „ëµ ê°€ì´ë“œ ì‹œë®¬ë ˆì´í„°")
# st.info("ğŸ’¡ ë¶„ì„ íš¨ìœ¨ì„ ìœ„í•´ ìƒìœ„ 30ê°œì˜ ì£¼ìš” íƒ€ê²Ÿ ì„¸ì…˜ì„ ìš”ì•½í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")

# left_col, right_col = st.columns([4, 6])

# with left_col:
#     st.subheader("ğŸ“¥ íƒ€ê²Ÿ ì„¸ì…˜ ë¦¬ìŠ¤íŠ¸ (TOP 30)")

#     labels = [f"ì„¸ì…˜ ë¶„ì„ ëŒ€ìƒ #{i+1}" for i in range(len(df))]
#     selected_label = st.selectbox("ë¶„ì„í•  ì„¸ì…˜ ì„ íƒ", labels)

#     group_id = labels.index(selected_label) + 1
#     row = df.iloc[group_id - 1]

#     X_one = pd.DataFrame([row.drop("Revenue", errors="ignore")])

#     # adapter.predict_proba ì‚¬ìš©
#     proba = float(adapter.predict_proba(X_one).iloc[0])
#     risk = service.classify_risk(proba)
#     action = service.recommend_action(row.to_dict(), proba, group_id=group_id)

#     st.write("---")
#     st.metric("í˜ì´ì§€ ê°€ì¹˜ (Value)", f"{row.get('PageValues', 0):.2f}")
#     st.metric("ì´íƒˆë¥  (Bounce)", f"{row.get('BounceRates', 0)*100:.1f}%")
#     st.metric("ì²´ë¥˜ ì‹œê°„ (Duration)", f"{row.get('ProductRelated_Duration', 0):.1f}s")

# with right_col:
#     st.subheader("ğŸ‘¤ ê³ ê° í˜ë¥´ì†Œë‚˜ ì§„ë‹¨")

#     # 30ê°œ ì„¸ì…˜ â†’ ì´ë¯¸ì§€ 10ê°œ ìˆœí™˜ ë§¤í•‘
#     image_key = ((group_id - 1) % 10) + 1
#     img_bytes = load_image_from_drive(GROUP_IMAGE_MAP.get(image_key))

#     if img_bytes:
#         st.image(img_bytes, width=420)
#     else:
#         st.warning("âš ï¸ í˜ë¥´ì†Œë‚˜ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

#     st.write(f"**ì‹¤ì‹œê°„ êµ¬ë§¤ ì „í™˜ í™•ë¥ : {proba*100:.1f}%**")
#     st.progress(proba)

#     if risk == "HIGH_RISK":
#         status_text = "ğŸš¨ ì´íƒˆ ìœ„í—˜ ë†’ìŒ: ì¦‰ê°ì ì¸ ì¼€ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
#     elif risk == "OPPORTUNITY":
#         status_text = "âš ï¸ ë§ì„¤ì´ëŠ” ë‹¨ê³„: í˜œíƒì´ ì „í™˜ì˜ ì—´ì‡ ì…ë‹ˆë‹¤."
#     else:
#         status_text = "âœ… êµ¬ë§¤ ìœ ë ¥ ìƒíƒœ: íë¦„ì„ ë°©í•´í•˜ì§€ ë§ˆì„¸ìš”."

#     st.markdown("### ğŸ“Œ ì¶”ì²œ ë§ˆì¼€íŒ… ì „ëµ")
#     st.markdown(f"**{status_text}**")
#     st.markdown(f"> {action}")

# with st.expander("ğŸ” ì„ íƒëœ ì„¸ì…˜ ìƒì„¸ ë¡œê·¸ í™•ì¸"):
#     st.table(pd.DataFrame([row]).T)

# GROUP_IMAGE_MAP = {
#     1: "https://drive.google.com/uc?id=1C_FatsRQqIQPnygwx3McU4NcZZiRiBFp",
#     2: "https://drive.google.com/uc?id=1KB0J8zrm7ZFC4FvAcL3Z1r831ZBZpKJR",
#     3: "https://drive.google.com/uc?id=1n7l5AhZIU46u7vD6UxBk7xWSaraVMDao",
#     4: "https://drive.google.com/uc?id=1tmKyCJ_qhVv0050H9DPNdckhgXV0QwBt",
#     5: "https://drive.google.com/uc?id=1o3XvxRP9-iN80cO8T_aVPoA04CMk94hh",
#     6: "https://drive.google.com/uc?id=1QUXQMxvR0b7Gyx-KsHidAA6kVg8nFp_Y",
#     7: "https://drive.google.com/uc?id=1yJ5An-fs3J8PlADZ4NYUp4ySiFh4Okct",
#     8: "https://drive.google.com/uc?id=1u7eZMaBMpQ2aqg5A9BRw5BP1eKu6Kw4m",
#     9: "https://drive.google.com/uc?id=1kU9k2cCKkHRNnHhLCYKy4QsIQdTYAyCc",
#     10:"https://drive.google.com/uc?id=1kZpn2fKK2yC1PImdHo2CwQ61DVWf9qSy",
# }

# ì´ë¯¸ì§€ 1 "ğŸš¨ [ì‹¬íì†Œìƒìˆ  ì‹œê¸‰] ê³ ê°ë‹˜ì´ 'ë’¤ë¡œ ê°€ê¸°' ë²„íŠ¼ê³¼ ì¸ íƒ€ëŠ” ì¤‘ì…ë‹ˆë‹¤! í˜œíƒ í•œ ì¤„ ìš”ì•½ì´ë‘ ë² ìŠ¤íŠ¸ ë¦¬ë·°ë¡œ ë©±ì‚´ ì¡ê³  ëŒì–´ì™€ì•¼ í•´ìš”!"
# ì´ë¯¸ì§€ 2. "ğŸšª 'ë‚˜ ì§€ê¸ˆ ë‚˜ê°„ë‹¤?'ë¼ê³  ì˜¨ëª¸ìœ¼ë¡œ ì™¸ì¹˜ëŠ” ì¤‘! 3ì´ˆ ì•ˆì— í• ì¸ ì¿ í°ì´ë‚˜ ë¬´ë£Œë°°ì†¡ ì•ˆ ë³´ì—¬ì£¼ë©´ ì˜ì˜ ë‚¨ë‚¨ì…ë‹ˆë‹¤. ë¹¨ë¦¬ìš”!"
# ì´ë¯¸ì§€ 3. "ğŸ§¯ ê´€ì‹¬ì´ë¼ëŠ” ë¶ˆì”¨ê°€ ìƒê¸°ê¸°ë„ ì „ì— ë¡œê·¸ì•„ì›ƒ ê°! ëœë”© í˜ì´ì§€ì— ì¸ê¸° ìƒí’ˆì´ë‘ ì‹ ë¢° íŒíŒ ê°€ëŠ” ì¸ì¦ë§ˆí¬ë¡œ ë„ë°°í•´ì„œ ëˆˆê¸¸ì„ ëºìœ¼ì„¸ìš”!"
# ì´ë¯¸ì§€ 4.  "ğŸª ì‚´ì§ ì†”ê¹ƒí•´ ë³´ì´ì§€ë§Œ, ë¡œë”© 1ì´ˆë§Œ ëŠ¦ì–´ë„ ë– ë‚  ë¶„ì…ë‹ˆë‹¤. ë³µì¡í•œ ê±° ë‹¤ ë¹¼ê³  í•µì‹¬ í˜œíƒë§Œ ì½”ì•ì— ë“¤ì´ë¯¸ì„¸ìš”!"
# ì´ë¯¸ì§€ 5. "âš ï¸ ì´ ì •ë„ë©´ 'ë°€ë‹¹' ê³ ìˆ˜ë„¤ìš”. ì‚´ê¹Œ ë§ê¹Œ ê³ ë¯¼í•˜ëŠ” ê²Œ ë³´ì…ë‹ˆë‹¤. 'ì˜¤ëŠ˜ë§Œ ì´ ê°€ê²©' ì½¤ë³´ í•œ ë°©ì´ë©´ ë°”ë¡œ ë„˜ì–´ì˜µë‹ˆë‹¤!"
# ì´ë¯¸ì§€ 6. "ğŸ‘€ ì¥ë°”êµ¬ë‹ˆì— ë„£ì„ê¹Œ ë§ê¹Œ 100ë²ˆ ê³ ë¯¼ ì¤‘! 'ìµœì €ê°€ ë³´ì¥'ì´ë‚˜ 'ë¹ ë¥¸ ë°°ì†¡' ì •ë³´ë¡œ ê³ ê°ë‹˜ì˜ ìš°ìœ ë¶€ë‹¨í•¨ì— ë§ˆì¹¨í‘œë¥¼ ì°ì–´ì£¼ì„¸ìš”!"
# ì´ë¯¸ì§€ 7. "ğŸ¯ ëŒ€ì–´ ë‚šê¸° ì§ì „ì…ë‹ˆë‹¤! 'ì‚¬ëŒë“¤ì´ ì´ ì œí’ˆ ì¹­ì°¬ì„ ì´ë ‡ê²Œ ë§ì´ í•´ìš”'ë¼ê³  ì‚¬íšŒì  ì¦ê±°(í›„ê¸°/ë³„ì )ë¥¼ ë§ˆêµ¬ íˆ¬ì²™í•˜ì„¸ìš”!"
# ì´ë¯¸ì§€ 8. "ğŸ”¥ [ê²°ì œ ì§ì „] ì¡°ê¸ˆë§Œ ë°€ë©´ ì¹´ë“œ ìŠ¬ë˜ì‹œ! í•œì •íŒ ì¿ í°ì´ë‚˜ 'ë¬´ë£Œë°°ì†¡ê¹Œì§€ ì–¼ë§ˆ ì•ˆ ë‚¨ì•˜ì–´ìš”'ë¼ëŠ” ë©˜íŠ¸ë¡œ ë¶ˆì„ ì§€í”¼ì„¸ìš”!"
# ì´ë¯¸ì§€ 9. "ğŸ›’ ì´ë¯¸ ë§ˆìŒì€ ê²°ì œ ì™„ë£Œ! ê´œíˆ íŒì—… ë„ì›Œì„œ ë°©í•´í•˜ì§€ ë§ê³ , ì¿ í° ìë™ ì ìš©í•´ì„œ ë ˆë“œì¹´í« ê¹”ì•„ë“œë¦½ì‹œë‹¤. ê²°ì œ ê¸¸ë§Œ ê±·ê²Œ í•˜ì„¸ìš”!"
# ì´ë¯¸ì§€ 10.  "âœ… [í™•ì • ì „í™˜] ì´ë¶„ì€ ìˆ¨ë§Œ ì‰¬ì–´ë„ êµ¬ë§¤í•˜ì‹¤ ë¶„ì…ë‹ˆë‹¤! ì¶”ê°€ ì˜ì—…ì€ ì‚¬ì¹˜ì¼ ë¿. ê°€ë³ê²Œ 'í•¨ê»˜ ì‚¬ë©´ ì¢‹ì€ ê¿€í…œ' í•˜ë‚˜ë§Œ ìŠ¥- ë˜ì ¸ë³´ì„¸ìš”."
# ì´ëŸ° ìƒí™©ì— ë§ëŠ” ì‚¬ëŒ ì–¼êµ´ ì´ë¯¸ì§€ 10ê°œ ê°ê° 1ì¥ì”© ìš©ëŸ‰ì€ ì‘ê²Œ ì œì‘í•´ì¤˜


import streamlit as st
import pandas as pd
import sys
import requests
from io import BytesIO
from pathlib import Path

from ui.header import render_header

# =========================================================
# [STEP 0] Streamlit ê¸°ë³¸ ì„¤ì •
# - (ëˆ„ë½ë˜ê¸° ì‰¬ìš´ ë¶€ë¶„ì´ë¼ ëª…ì‹œì ìœ¼ë¡œ ë³µêµ¬)
# =========================================================
st.set_page_config(
    page_title="Marketing Action Guide",
    page_icon="ğŸ¯",
    layout="wide"
)

# =========================================================
# [STEP 1] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (Path ê¸°ë°˜, OS ë…ë¦½)
# =========================================================
CURRENT_FILE = Path(__file__).resolve()
APP_DIR = CURRENT_FILE.parents[1]
PROJECT_ROOT = CURRENT_FILE.parents[2]

if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))
if str(APP_DIR) not in sys.path:
    sys.path.insert(0, str(APP_DIR))

# =========================================================
# [STEP 2] ëª¨ë“ˆ ì„í¬íŠ¸
# =========================================================
from adapters.model_loader import JoblibArtifactLoader
from adapters.purchase_intent_pr_auc_adapter import PurchaseIntentPRAUCModelAdapter
from service.CustomerCareCenter import PurchaseIntentService

# =========================================================
# [STEP 3] ëª¨ë¸ ë¡œë”©
# - ğŸ”§ ìˆ˜ì • í•µì‹¬:
#   PurchaseIntentPRAUCModelAdapterëŠ” "ModelArtifact"ê°€ ì•„ë‹ˆë¼
#   "artifact_path(ê²½ë¡œ)"ë¥¼ ë°›ë„ë¡ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë¯€ë¡œ,
#   adapterì—ëŠ” ê²½ë¡œë¥¼ ì „ë‹¬í•´ì•¼ í•¨.
# =========================================================
@st.cache_resource
def init_service():
    artifact_path = PROJECT_ROOT / "app" / "artifacts" / "best_pr_auc_balancedrf.joblib"

    # ğŸ”§ ìˆ˜ì •: íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬ (ë‹¤ë¥¸ PCì—ì„œë„ ì›ì¸ íŒŒì•… ì‰¬ì›€)
    if not artifact_path.exists():
        st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {artifact_path}")
        st.stop()

    # ğŸ”§ ìˆ˜ì •: adapterëŠ” "artifact ê°ì²´"ê°€ ì•„ë‹ˆë¼ "ê²½ë¡œ"ë¥¼ ë°›ëŠ”ë‹¤
    # (Path ê°ì²´ë„ PathLikeë¡œ ë™ì‘í•˜ì§€ë§Œ, êµ¬í˜„ì²´ì— ë”°ë¼ strì´ ì•ˆì „í•  ìˆ˜ ìˆìŒ)
    adapter = PurchaseIntentPRAUCModelAdapter(str(artifact_path))

    # service ìƒì„±
    service = PurchaseIntentService(
        adapter=adapter,
    artifact_path=str(artifact_path))

    # (ì„ íƒ) artifactë¥¼ ê¼­ ë°˜í™˜í•´ì•¼ í•œë‹¤ë©´ loaderë¡œ ë”°ë¡œ ë¡œë“œí•´ì„œ ë°˜í™˜ ê°€ëŠ¥
    # ë‹¨, adapterê°€ ë‚´ë¶€ì—ì„œë„ ë¡œë“œí•  ìˆ˜ ìˆì–´ "ì¤‘ë³µ ë¡œë”©"ì´ ë  ìˆ˜ ìˆìŒ.
    loader = JoblibArtifactLoader(str(artifact_path))
    artifact = loader.load()

    return service, adapter, artifact


service, adapter, artifact = init_service()

# =========================================================
# [STEP 4] ë°ì´í„° ë¡œë“œ (UIìš© ìƒ˜í”Œ)
# =========================================================
@st.cache_data
def load_data():
    data_path = PROJECT_ROOT / "data" / "processed" / "test.csv"
    if not data_path.exists():
        st.error(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_path}")
        st.stop()
    return pd.read_csv(data_path)

# ê¸°ì¡´ ìœ ì§€: 30ê°œ ì„¸ì…˜ ì‚¬ìš©
df = load_data().head(30)

# =========================================================
# [í•µì‹¬ ì¶”ê°€] ì…ë ¥ DataFrameì„ ëª¨ë¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬/ë³´ì •
# - ëª¨ë¸ì´ í•™ìŠµí•œ ì»¬ëŸ¼ì´ dfì— ì—†ìœ¼ë©´ ColumnTransformerì—ì„œ ë°”ë¡œ í„°ì§
# - ë”°ë¼ì„œ "ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡"ì„ ì¶”ì¶œí•˜ê³ , X_oneì„ ê·¸ ìŠ¤í‚¤ë§ˆì— ë§ì¶˜ë‹¤
# =========================================================
@st.cache_data
def get_model_expected_columns() -> list[str]:
    """
    ëª¨ë¸ íŒŒì´í”„ë¼ì¸ì´ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ì»¬ëŸ¼ ëª©ë¡ì„ ì¶”ì¶œí•œë‹¤.
    - sklearn 1.0+ ì—ì„œ Pipeline/Estimatorì— feature_names_in_ê°€ ì¡´ì¬í•  ìˆ˜ ìˆìŒ
    - ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ artifact/metaì— ì €ì¥ëœ ì»¬ëŸ¼ ì •ë³´ë¥¼ íƒìƒ‰
    """
    # 1) adapterê°€ pipelineì„ ë“¤ê³  ìˆëŠ” ê²½ìš° (ê°€ì¥ í”í•œ ì¼€ì´ìŠ¤)
    pipe = getattr(adapter, "pipeline", None)
    if pipe is not None and hasattr(pipe, "feature_names_in_"):
        return list(pipe.feature_names_in_)

    # 2) artifact.pipelineë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ìš°
    art = artifact
    if hasattr(art, "pipeline") and hasattr(art.pipeline, "feature_names_in_"):
        return list(art.pipeline.feature_names_in_)

    # 3) metaì— ì»¬ëŸ¼ ëª©ë¡ì„ ì €ì¥í•´ë‘” ê²½ìš° (íŒ€ ê·œì•½ì— ë”°ë¼ í‚¤ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    if hasattr(art, "meta") and isinstance(art.meta, dict):
        for key in ["feature_cols", "feature_columns", "columns", "X_columns", "input_columns"]:
            if key in art.meta and isinstance(art.meta[key], (list, tuple)) and len(art.meta[key]) > 0:
                return list(art.meta[key])

    # 4) ìµœí›„ì˜ ìˆ˜ë‹¨: í˜„ì¬ dfì˜ feature ì»¬ëŸ¼ì„ ì‚¬ìš© (Revenue ì œì™¸)
    #    (ì´ ì¼€ì´ìŠ¤ëŠ” "ëª¨ë¸ê³¼ df ì»¬ëŸ¼ì´ ì›ë˜ ë™ì¼"í•œ ìƒí™©ì—ì„œë§Œ ì•ˆì „)
    fallback = [c for c in df.columns if c != "Revenue"]
    return fallback


EXPECTED_COLS = get_model_expected_columns()


def align_features_to_model_schema(row: pd.Series) -> pd.DataFrame:
    """
    ë‹¨ì¼ rowë¥¼ ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ì»¬ëŸ¼ ìŠ¤í‚¤ë§ˆ(EXPECTED_COLS)ì— ë§ì¶° DataFrame(1í–‰)ìœ¼ë¡œ ë§Œë“ ë‹¤.
    - dfì— ì—†ëŠ” ì»¬ëŸ¼ì€ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€
    - dfì— ìˆì§€ë§Œ ëª¨ë¸ì´ ê¸°ëŒ€í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ì€ ì œê±°
    - ì»¬ëŸ¼ ìˆœì„œë¥¼ EXPECTED_COLSë¡œ ì •ë ¬
    """
    # íƒ€ê²Ÿ/ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±° (RevenueëŠ” ì˜ˆì¸¡ ì…ë ¥ì—ì„œ ì œì™¸)
    feature_row = row.drop("Revenue", errors="ignore")

    # 1í–‰ DataFrame ìƒì„±
    X = pd.DataFrame([feature_row.to_dict()])

    # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê³ /ì¶”ê°€
    # ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ì›€ (ë²”ì£¼í˜•ì´ì–´ë„ 0ìœ¼ë¡œ ë‘ëŠ” ì´ìœ : ì „ì²˜ë¦¬ì—ì„œ handle_unknown/ë¹ˆê°’ ì²˜ë¦¬ ê¸°ëŒ€)
    # í•„ìš” ì‹œ ì•„ë˜ default ê°’ì„ "Unknown" ê°™ì€ ë¬¸ìì—´ë¡œ ë°”ê¾¸ëŠ” ê²ƒë„ ê°€ëŠ¥
    for col in EXPECTED_COLS:
        if col not in X.columns:
            X[col] = 0

    # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ì€ ì œê±°
    X = X[EXPECTED_COLS]

    return X

# =========================================================
# [ìœ ì§€] ê·¸ë£¹ë³„ Google Drive ì´ë¯¸ì§€ (10ê°œ)
# =========================================================
GROUP_IMAGE_MAP = {
    1: "https://drive.google.com/uc?id=1C_FatsRQqIQPnygwx3McU4NcZZiRiBFp",
    2: "https://drive.google.com/uc?id=1KB0J8zrm7ZFC4FvAcL3Z1r831ZBZpKJR",
    3: "https://drive.google.com/uc?id=1n7l5AhZIU46u7vD6UxBk7xWSaraVMDao",
    4: "https://drive.google.com/uc?id=1tmKyCJ_qhVv0050H9DPNdckhgXV0QwBt",
    5: "https://drive.google.com/uc?id=1o3XvxRP9-iN80cO8T_aVPoA04CMk94hh",
    6: "https://drive.google.com/uc?id=1QUXQMxvR0b7Gyx-KsHidAA6kVg8nFp_Y",
    7: "https://drive.google.com/uc?id=1yJ5An-fs3J8PlADZ4NYUp4ySiFh4Okct",
    8: "https://drive.google.com/uc?id=1u7eZMaBMpQ2aqg5A9BRw5BP1eKu6Kw4m",
    9: "https://drive.google.com/uc?id=1kU9k2cCKkHRNnHhLCYKy4QsIQdTYAyCc",
    10: "https://drive.google.com/uc?id=1kZpn2fKK2yC1PImdHo2CwQ61DVWf9qSy",
}

@st.cache_data
def load_image_from_drive(url: str):
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            return BytesIO(response.content)
    except Exception:
        return None
    return None

# =========================================================
# [ì¶”ê°€] ê°œë°œ ì¤‘ ìºì‹œ ì´ˆê¸°í™” ë²„íŠ¼
# - Streamlit ìºì‹œ ë•Œë¬¸ì— ì½”ë“œ ìˆ˜ì •ì´ ë°˜ì˜ ì•ˆ ë˜ëŠ” ìƒí™© ë°©ì§€
# =========================================================
with st.sidebar:
    if st.button("ìºì‹œ ì´ˆê¸°í™”(ê°œë°œìš©)"):
        st.cache_data.clear()
        st.cache_resource.clear()
        st.rerun()

# =========================================================
# [UI]
# =========================================================
render_header()
st.title("ğŸ¯ ë§ˆì¼€íŒ… ì „ëµ ê°€ì´ë“œ ì‹œë®¬ë ˆì´í„°")
st.info("ğŸ’¡ ë¶„ì„ íš¨ìœ¨ì„ ìœ„í•´ ìƒìœ„ 30ê°œì˜ ì£¼ìš” íƒ€ê²Ÿ ì„¸ì…˜ì„ ìš”ì•½í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")

left_col, right_col = st.columns([4, 6])

with left_col:
    st.subheader("ğŸ“¥ íƒ€ê²Ÿ ì„¸ì…˜ ë¦¬ìŠ¤íŠ¸ (TOP 30)")

    labels = [f"ì„¸ì…˜ ë¶„ì„ ëŒ€ìƒ #{i+1}" for i in range(len(df))]
    selected_label = st.selectbox("ë¶„ì„í•  ì„¸ì…˜ ì„ íƒ", labels)

    group_id = labels.index(selected_label) + 1
    row = df.iloc[group_id - 1]

    # =========================================================
    # [í•µì‹¬ ìˆ˜ì •] ëª¨ë¸ ê¸°ì¤€ ìŠ¤í‚¤ë§ˆë¡œ X_one ì •ë ¬/ë³´ì •
    # =========================================================
    X_one = align_features_to_model_schema(row)

    # adapter.predict_proba ì‚¬ìš©
    proba = float(adapter.predict_proba(X_one).iloc[0])
    risk = service.classify_risk(proba)
    action = service.recommend_action(row.to_dict(), proba, group_id=group_id)

    st.write("---")
    st.metric("í˜ì´ì§€ ê°€ì¹˜ (Value)", f"{row.get('PageValues', 0):.2f}")
    st.metric("ì´íƒˆë¥  (Bounce)", f"{row.get('BounceRates', 0)*100:.1f}%")
    st.metric("ì²´ë¥˜ ì‹œê°„ (Duration)", f"{row.get('ProductRelated_Duration', 0):.1f}s")

with right_col:
    st.subheader("ğŸ‘¤ ê³ ê° í˜ë¥´ì†Œë‚˜ ì§„ë‹¨")

    # 30ê°œ ì„¸ì…˜ â†’ ì´ë¯¸ì§€ 10ê°œ ìˆœí™˜ ë§¤í•‘
    image_key = ((group_id - 1) % 10) + 1
    img_bytes = load_image_from_drive(GROUP_IMAGE_MAP.get(image_key))

    if img_bytes:
        st.image(img_bytes, width=420)
    else:
        st.warning("âš ï¸ í˜ë¥´ì†Œë‚˜ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.write(f"**ì‹¤ì‹œê°„ êµ¬ë§¤ ì „í™˜ í™•ë¥ : {proba*100:.1f}%**")
    st.progress(proba)

    if risk == "HIGH_RISK":
        status_text = "ğŸš¨ ì´íƒˆ ìœ„í—˜ ë†’ìŒ: ì¦‰ê°ì ì¸ ì¼€ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    elif risk == "OPPORTUNITY":
        status_text = "âš ï¸ ë§ì„¤ì´ëŠ” ë‹¨ê³„: í˜œíƒì´ ì „í™˜ì˜ ì—´ì‡ ì…ë‹ˆë‹¤."
    else:
        status_text = "âœ… êµ¬ë§¤ ìœ ë ¥ ìƒíƒœ: íë¦„ì„ ë°©í•´í•˜ì§€ ë§ˆì„¸ìš”."

    st.markdown("### ğŸ“Œ ì¶”ì²œ ë§ˆì¼€íŒ… ì „ëµ")
    st.markdown(f"**{status_text}**")
    st.markdown(f"> {action}")

with st.expander("ğŸ” ì„ íƒëœ ì„¸ì…˜ ìƒì„¸ ë¡œê·¸ í™•ì¸"):
    st.table(pd.DataFrame([row]).T)
